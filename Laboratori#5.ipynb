{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 5 - Autocodificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Cheese  Carcass_meat   Other_meat   Fish  Fats_and_oils   Sugars  \\\n",
      "England       105            245          685   147             193     156   \n",
      "Wales         103            227          803   160             235     175   \n",
      "Scotland      103            242          750   122             184     147   \n",
      "N.Ireland      66            267          586    93             209     139   \n",
      "\n",
      "           Fresh_potatoes   Fresh_Veg   Other_Veg   Processed_potatoes   \\\n",
      "England                720         253         488                  198   \n",
      "Wales                  874         265         570                  203   \n",
      "Scotland               566         171         418                  220   \n",
      "N.Ireland             1033         143         355                  187   \n",
      "\n",
      "           Processed_Veg   Fresh_fruit   Cereals   Beverages  Soft_drinks   \\\n",
      "England               360          1102      1472         57          1374   \n",
      "Wales                 365          1137      1582         73          1256   \n",
      "Scotland              337           957      1462         53          1572   \n",
      "N.Ireland             334           674      1494         47          1506   \n",
      "\n",
      "           Alcoholic_drinks   Confectionery   \n",
      "England                  375              54  \n",
      "Wales                    475              64  \n",
      "Scotland                 458              62  \n",
      "N.Ireland                135              41  \n",
      "           Cheese  Carcass_meat   Other_meat         Fish  Fats_and_oils   \\\n",
      "count    4.000000           4.00     4.000000    4.000000        4.000000   \n",
      "mean    94.250000         245.25   706.000000  130.500000      205.250000   \n",
      "std     18.856917          16.50    93.427334   29.557853       22.366269   \n",
      "min     66.000000         227.00   586.000000   93.000000      184.000000   \n",
      "25%     93.750000         238.25   660.250000  114.750000      190.750000   \n",
      "50%    103.000000         243.50   717.500000  134.500000      201.000000   \n",
      "75%    103.500000         250.50   763.250000  150.250000      215.500000   \n",
      "max    105.000000         267.00   803.000000  160.000000      235.000000   \n",
      "\n",
      "          Sugars  Fresh_potatoes   Fresh_Veg   Other_Veg   \\\n",
      "count    4.00000         4.000000    4.000000    4.000000   \n",
      "mean   154.25000       798.250000  208.000000  457.750000   \n",
      "std     15.47848       200.755863   60.188592   92.471167   \n",
      "min    139.00000       566.000000  143.000000  355.000000   \n",
      "25%    145.00000       681.500000  164.000000  402.250000   \n",
      "50%    151.50000       797.000000  212.000000  453.000000   \n",
      "75%    160.75000       913.750000  256.000000  508.500000   \n",
      "max    175.00000      1033.000000  265.000000  570.000000   \n",
      "\n",
      "       Processed_potatoes   Processed_Veg   Fresh_fruit      Cereals   \\\n",
      "count             4.000000        4.000000      4.000000     4.000000   \n",
      "mean            202.000000      349.000000    967.500000  1502.500000   \n",
      "std              13.735599       15.769168    210.612599    54.659552   \n",
      "min             187.000000      334.000000    674.000000  1462.000000   \n",
      "25%             195.250000      336.250000    886.250000  1469.500000   \n",
      "50%             200.500000      348.500000   1029.500000  1483.000000   \n",
      "75%             207.250000      361.250000   1110.750000  1516.000000   \n",
      "max             220.000000      365.000000   1137.000000  1582.000000   \n",
      "\n",
      "       Beverages  Soft_drinks   Alcoholic_drinks   Confectionery   \n",
      "count   4.000000      4.000000           4.000000        4.000000  \n",
      "mean   57.500000   1427.000000         360.750000       55.250000  \n",
      "std    11.120552    140.612944         156.712848       10.436315  \n",
      "min    47.000000   1256.000000         135.000000       41.000000  \n",
      "25%    51.500000   1344.500000         315.000000       50.750000  \n",
      "50%    55.000000   1440.000000         416.500000       58.000000  \n",
      "75%    61.000000   1522.500000         462.250000       62.500000  \n",
      "max    73.000000   1572.000000         475.000000       64.000000  \n",
      "             Cheese  Carcass_meat   Other_meat       Fish  Fats_and_oils   \\\n",
      "England    0.658275      -0.017495    -0.259546  0.644585       -0.632429   \n",
      "Wales      0.535805      -1.277169     1.198856  1.152440        1.535899   \n",
      "Scotland   0.535805      -0.227441     0.543811 -0.332059       -1.097071   \n",
      "N.Ireland -1.729885       1.522105    -1.483121 -1.464967        0.193601   \n",
      "\n",
      "             Sugars  Fresh_potatoes   Fresh_Veg   Other_Veg   \\\n",
      "England    0.130551        -0.450076    0.863312    0.377736   \n",
      "Wales      1.547958         0.435696    1.093528    1.401682   \n",
      "Scotland  -0.540853        -1.335847   -0.709834   -0.496364   \n",
      "N.Ireland -1.137656         1.350227   -1.247006   -1.283054   \n",
      "\n",
      "           Processed_potatoes   Processed_Veg   Fresh_fruit   Cereals   \\\n",
      "England              -0.336265        0.805477      0.737407 -0.644322   \n",
      "Wales                 0.084066        1.171603      0.929297  1.679463   \n",
      "Scotland              1.513193       -0.878702     -0.057567 -0.855575   \n",
      "N.Ireland            -1.260994       -1.098378     -1.609137 -0.179565   \n",
      "\n",
      "           Beverages  Soft_drinks   Alcoholic_drinks   Confectionery   \n",
      "England    -0.051917     -0.435231           0.104998       -0.138303  \n",
      "Wales       1.609440     -1.404236           0.841823        0.968122  \n",
      "Scotland   -0.467257      1.190727           0.716563        0.746837  \n",
      "N.Ireland  -1.090266      0.648741          -1.663384       -1.576656  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# 1.1 Cargar los datos\n",
    "df = pd.read_csv('UK_foods.csv', index_col=0)  # Suponiendo que la primera columna contiene los nombres de los alimentos\n",
    "\n",
    "# Transponer el DataFrame para que los países sean las observaciones y los alimentos las características\n",
    "df = df.transpose()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# 1.2 Exploración básica\n",
    "print(df.describe())\n",
    "\n",
    "# 1.3 Normalización\n",
    "scaler = StandardScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
    "print(df_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 3ms/step - loss: 1.2371\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2355\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2341\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 331us/step - loss: 1.2330\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2315\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2303\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.2289\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2276\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2262\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2249\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2235\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2221\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 1.2209\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2195\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2181\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 371us/step - loss: 1.2171\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2157\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2141\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2127\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2114\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2101\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2088\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2077\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2060\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.2046\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2034\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 857us/step - loss: 1.2021\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2005\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1994\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1979\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1963\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1949\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1936\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1924\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1908\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1894\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1881\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1866\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1849\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1840\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1820\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1808\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1793\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1776\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1766\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1748\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1732\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1718\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1700\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1685\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1672\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1655\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1640\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1626\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.1606\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 978us/step - loss: 1.1591\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1571\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1557\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1536\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1520\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1504\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1483\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1473\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1448\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1427\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1409\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1389\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1373\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1354\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1331\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1313\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1290\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1267\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1246\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1225\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1206\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1188\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1156\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1137\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1119\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1089\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1065\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1049\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1021\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0997\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0972\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0946\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0922\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0905\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0871\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.0847\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0829\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0801\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0774\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 399us/step - loss: 1.0756\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0733\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0706\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0677\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0653\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0628\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 1.0613\n",
      "Loss: 1.061302661895752\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# 2.1 Usar todas las observaciones para entrenar\n",
    "X_train = df_normalized.values\n",
    "\n",
    "# 2.2 Definir la arquitectura\n",
    "input_layer = layers.Input(shape=(X_train.shape[1],))\n",
    "encoder = layers.Dense(4, activation='relu')(input_layer)\n",
    "bottleneck = layers.Dense(2, activation='relu')(encoder)\n",
    "decoder = layers.Dense(4, activation='relu')(bottleneck)\n",
    "output_layer = layers.Dense(X_train.shape[1], activation='sigmoid')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# 2.3 Compilación y entrenamiento\n",
    "autoencoder.compile(loss = \"mse\",\n",
    "                        optimizer = SGD(lr = 1.5))\n",
    "autoencoder.fit(X_train, X_train, epochs=100, batch_size=1)\n",
    "\n",
    "# 2.4 Evaluación\n",
    "loss = autoencoder.evaluate(X_train, X_train)\n",
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Use the autoencoder to reduce the dimensions of the dataset to 2.\n",
    "encoded_data = encoder.predict(df_uk_foods_normalized.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codificado_2dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esteb\\OneDrive\\Documents\\GitHub\\Lab5-Autocodificadores\\Laboratori#4.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esteb/OneDrive/Documents/GitHub/Lab5-Autocodificadores/Laboratori%234.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Visualización con matplotlib\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esteb/OneDrive/Documents/GitHub/Lab5-Autocodificadores/Laboratori%234.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esteb/OneDrive/Documents/GitHub/Lab5-Autocodificadores/Laboratori%234.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mscatter(codificado_2dim[:, \u001b[39m0\u001b[39m], codificado_2dim[:, \u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(y)), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esteb/OneDrive/Documents/GitHub/Lab5-Autocodificadores/Laboratori%234.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, country \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(y):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esteb/OneDrive/Documents/GitHub/Lab5-Autocodificadores/Laboratori%234.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mannotate(country, (codificado_2dim[i, \u001b[39m0\u001b[39m], codificado_2dim[i, \u001b[39m1\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'codificado_2dim' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Supongamos que y es una lista de países para etiquetar los puntos en la gráfica.\n",
    "y = df.index  # Usando el índice de tu DataFrame que son los nombres de los países.\n",
    "\n",
    "# Visualización con matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(encoded_data[:, 0], encoded_data[:, 1], c=range(len(y)), cmap='viridis')\n",
    "for i, country in enumerate(y):\n",
    "    plt.annotate(country, (encoded_data[i, 0], encoded_data[i, 1]))\n",
    "plt.colorbar().set_label('Index of Country')\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.title(\"2D representation of encoded data with Matplotlib\")\n",
    "plt.show()\n",
    "\n",
    "# Visualización con plotly\n",
    "fig = px.scatter(x=encoded_data[:, 0], \n",
    "                 y=encoded_data[:, 1], \n",
    "                 color=y,\n",
    "                 labels={'color': 'Country'},\n",
    "                 width=700,\n",
    "                 height=500,\n",
    "                 title=\"2D representation of encoded data with Plotly\")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
